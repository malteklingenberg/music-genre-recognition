{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982cf141-c66b-4ef3-b470-c8e82511b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "librosa.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c57e2-87be-4bc4-a3d7-efe72884cb7a",
   "metadata": {},
   "source": [
    "### build DataFrame of all file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b91ec2-288d-46bf-b0e6-f75c3e99bd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTER THE PATH TO YOUR GTZAN DIRECTORY HERE\n",
    "gtzan_base_path = Path('path/to/gtzan/Data/genres_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c543da-95f2-44e2-95a4-39bfb613d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_genre = []\n",
    "col_file = []\n",
    "col_path = []\n",
    "for genre_path in gtzan_base_path.iterdir():\n",
    "    genre = genre_path.name\n",
    "    for file_path in genre_path.iterdir():\n",
    "        file = file_path.name\n",
    "        col_genre.append(genre)\n",
    "        col_file.append(file)\n",
    "        col_path.append(file_path)\n",
    "\n",
    "files = pd.DataFrame(index=pd.Index(data=col_file, name='file'), data={'genre': col_genre, 'path': col_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e24d2c-2be1-4248-a1fc-a1ec68ccd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ab86a-b317-4289-9878-979c659687ac",
   "metadata": {},
   "source": [
    "## feature extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f05a2-5d28-49b2-85b0-3b64f9e0af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_energy_rate(y, frame_length):\n",
    "    frame_energies = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=frame_length, center=False)[0]\n",
    "    mean_energy = np.mean(frame_energies)\n",
    "    return sum(frame_energies < mean_energy) / len(frame_energies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8b0e77-7069-414c-954b-fe77f4cd8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_flux(y, frame_length):\n",
    "    frame_stft = abs(librosa.stft(y=y, n_fft=frame_length, hop_length=frame_length, center=False))\n",
    "    # normalise spectrum per frame (catch case where frame only has silence)\n",
    "    frame_stft_max = np.max(frame_stft, axis=0)\n",
    "    frame_stft_max[frame_stft_max == 0] = 1\n",
    "    frame_stft /= frame_stft_max\n",
    "\n",
    "    spectral_diff = frame_stft[:,:-1] - frame_stft[:,1:]\n",
    "    spectral_flux = np.linalg.norm(spectral_diff, axis=0)\n",
    "    return spectral_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead6557e-9c84-46c2-84c0-3bc793569159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rhythm_features(y, sr, hop_length):\n",
    "    # calculate onset autocorrelation\n",
    "    onset_envelope = librosa.onset.onset_strength(y=y, sr=sr, hop_length=hop_length, center=False)\n",
    "    max_lag = 2 * sr // hop_length # 2sec = 30bpm, as we are only considering peaks between 40 and 200 bpm anyway\n",
    "    onset_autocorr = librosa.util.normalize(librosa.autocorrelate(onset_envelope, max_size=max_lag))\n",
    "    freqs = librosa.tempo_frequencies(onset_autocorr.shape[0], hop_length=hop_length, sr=sr)\n",
    "\n",
    "    # find overall sum of tempogram between 40 and 200 bpm\n",
    "    autocorr_freqs = list(filter(lambda x: 40 <= x[0] <= 200, zip(freqs, onset_autocorr)))\n",
    "    autocorr_sum = sum(x[1] for x in autocorr_freqs)\n",
    "\n",
    "    # find peaks of tempogram and corresponding frequencies\n",
    "    peak_indices, props = scipy.signal.find_peaks(onset_autocorr, height=0)\n",
    "    peaks = [[freqs[i], props['peak_heights'][n]] for n, i in enumerate(peak_indices)]\n",
    "\n",
    "    # limit to range of 40-200 bpm and sort by peak height\n",
    "    peaks = sorted(filter(lambda x: 40 <= x[0] <= 200, peaks), key=lambda x: x[1], reverse=True)\n",
    "    freq_0, amp_0 = peaks[0]\n",
    "    freq_1, amp_1 = peaks[1]\n",
    "\n",
    "    # calculate beat salience\n",
    "    # get peaks that are on (or one off) a multiple of the tempo (highest peak)\n",
    "    beat_salience_peaks = []\n",
    "    for i in peak_indices:\n",
    "        for j in [i-1, i, i+1]:\n",
    "            if freqs[j] in np.array([1/5, 1/4, 1/3, 1/2, 1, 2, 3, 4, 5]) * freq_0: # up to factor 5 (40 vs. 200 bpm)\n",
    "                beat_salience_peaks.append([freqs[j], onset_autocorr[j]])\n",
    "    # calculate log difference from 100 bpm and select closest peak\n",
    "    beat_salience_peaks = [[abs(np.log(freq) - np.log(100)), amp] for freq, amp in beat_salience_peaks]\n",
    "    beat_salience = sorted(beat_salience_peaks, key=lambda x: x[0])[0][1]\n",
    "\n",
    "    return amp_0 / autocorr_sum, amp_1 / autocorr_sum, amp_1 / amp_0, freq_0, freq_1, autocorr_sum, beat_salience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f78cae-af76-4d26-83dd-59d551923367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonal_features(y, sr, frame_length, hop_length):\n",
    "    # calculate chromagram and sum over all frames to get total amplitude per pitch class\n",
    "    chroma = librosa.feature.chroma_stft(y=y, sr=sr, n_fft=frame_length, hop_length=hop_length, tuning=0, center=False, norm=None)\n",
    "    chromagram_sum = np.sum(chroma)\n",
    "    chroma = [(pitch_class, amplitude) for pitch_class, amplitude in enumerate(np.sum(chroma, axis=1))]\n",
    "\n",
    "    # get pitch class and amplitude of highest peak, and pitch interval to second highest peak\n",
    "    peak_0, peak_1 = sorted(chroma, key=lambda x: x[1], reverse=True)[:2]\n",
    "    amp_0 = peak_0[1] / chromagram_sum\n",
    "    pitch_0 = (peak_0[0] * 7) % 12\n",
    "    pitch_interval = ((peak_0[0] * 7) % 12) - ((peak_1[0] * 7) % 12)\n",
    "    \n",
    "    return amp_0, pitch_0, pitch_interval, chromagram_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f701c4-6c2e-4689-a4eb-f7db5a2b1157",
   "metadata": {},
   "source": [
    "### playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9dbf2f-42ba-4175-bebf-9efee8c9e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = files.iloc[300].path\n",
    "print(path)\n",
    "x, sr = librosa.load(path)\n",
    "librosa.display.waveshow(x[100:200], sr=sr)\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7db4960-dcc6-4d58-95af-9c55166a3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.xlim(0, 5)\n",
    "librosa.display.waveshow(x, sr=sr, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90590b23-ba80-42f2-a8e3-f249d496384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.xlim(0, 5)\n",
    "S = np.abs(librosa.stft(y=x, n_fft=1024, hop_length=1024, center=False))\n",
    "librosa.display.specshow(librosa.amplitude_to_db(S, ref=np.max), sr=sr, y_axis='log', x_axis='time', alpha=0.5)\n",
    "\n",
    "c = librosa.feature.spectral_centroid(y=x, sr=sr, n_fft=1024, hop_length=1024, center=False)[0]\n",
    "c_minmax = (c - np.min(c))/(np.max(c) - np.min(c))\n",
    "\n",
    "r = librosa.feature.spectral_rolloff(y=x, sr=sr, n_fft=1024, hop_length=1024, center=False)[0]\n",
    "r_minmax = (r - np.min(r))/(np.max(r) - np.min(r))\n",
    "\n",
    "t = librosa.frames_to_time(np.array(range(len(c))), sr=sr*2, hop_length=1024)\n",
    "plt.plot(t, c, color='g')\n",
    "plt.plot(t, r, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022e2ee-df64-4a34-becb-724ddffe61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.xlim(0, 5)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr, n_mfcc=5, n_fft=1024, hop_length=1024, center=False)\n",
    "librosa.display.specshow(mfcc, x_axis='time')\n",
    "\n",
    "print(np.mean(mfcc, axis=1))\n",
    "print(np.var(mfcc, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4443d077-4e1f-47d6-bda8-7d6f50b63868",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.xlim(0, 5)\n",
    "chroma = librosa.feature.chroma_stft(y=x, sr=sr, hop_length=1024, tuning=0, center=False, norm=None)\n",
    "print(np.sum(chroma, axis=1))\n",
    "# NOTE: tuning=0 must be specified, as librosa.core.estimate_tuning is apparently bugged and crashes the kernel\n",
    "librosa.display.specshow(chroma, y_axis='chroma', x_axis='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8d5889-7cfa-48d6-8c45-1951fadd1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.xlim(0, 5)\n",
    "\n",
    "librosa.display.waveshow(x, sr=sr, alpha=0.4)\n",
    "\n",
    "o_env = librosa.onset.onset_strength(y=x, sr=sr, center=False)\n",
    "\n",
    "C = np.abs(librosa.cqt(y=x,sr=sr))\n",
    "o_env_cqt = librosa.onset.onset_strength(sr=sr, S=librosa.amplitude_to_db(C, ref=np.max))\n",
    "\n",
    "t = librosa.frames_to_time(np.array(range(len(o_env))), sr=sr, hop_length=512)\n",
    "plt.plot(t, o_env/np.max(o_env), label='mel')\n",
    "plt.plot(t, o_env_cqt/np.max(o_env_cqt), label='cqt')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c87a7-f426-4766-8925-61306f8ed64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "hop_length=128\n",
    "o_env = librosa.onset.onset_strength(y=x, sr=sr, hop_length=hop_length, center=False)\n",
    "tempogram = librosa.feature.tempogram(onset_envelope=o_env, sr=sr, hop_length=hop_length)\n",
    "tempogram = np.mean(tempogram, axis=1)\n",
    "max_lag = 2 * sr // hop_length\n",
    "ac_global = librosa.autocorrelate(o_env, max_size=max_lag)\n",
    "ac_global = librosa.util.normalize(ac_global)\n",
    "tempo = librosa.feature.tempo(onset_envelope=o_env, sr=sr, hop_length=hop_length)[0]\n",
    "print(tempo)\n",
    "freqs_autocorr = librosa.tempo_frequencies(ac_global.shape[0], hop_length=hop_length, sr=sr)\n",
    "freqs_tempogram = librosa.tempo_frequencies(tempogram.shape[0], hop_length=hop_length, sr=sr)\n",
    "plt.xlim((40,200))\n",
    "plt.xlabel('bpm')\n",
    "plt.plot(freqs_autocorr[1:], ac_global[1:])\n",
    "plt.plot(freqs_tempogram[1:], tempogram[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5f797c-d6a0-450d-b61b-fc3aa2e4f2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure 4.2\n",
    "plt.figure(figsize=(10,3.333))\n",
    "plt.xlim((40, 200))\n",
    "plt.xlabel('Tempo (bpm)')\n",
    "plt.ylim((0, 1))\n",
    "plt.ylabel('normalisierte Autokorrelation')\n",
    "plt.plot(freqs_autocorr[1:], ac_global[1:], label='Autokorrelation für disco.00000.wav')\n",
    "plt.plot([114.84, 114.84], [0, 1], '--', color='black', label='Peak 1 (114.84 bpm)')\n",
    "plt.plot([57.42, 57.42], [0, 1], '-.', color='black', label='Peak 2 (57.42 bpm)')\n",
    "plt.legend()\n",
    "plt.savefig('autocorrelation.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c16944f-e6f7-4045-8cd7-af9a9d2e2591",
   "metadata": {},
   "source": [
    "### calculate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54f78c-98ec-45f8-b8a9-a29055a113b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [                   # TIMBRE FEATURES\n",
    "            'spec_cent_mean',  # spectral centroid mean and variance\n",
    "            'spec_cent_var',\n",
    "            'spec_roll_mean',  # spectral rolloff mean and variance\n",
    "            'spec_roll_var',\n",
    "            'spec_flux_mean',  # spectral flux mean and variance\n",
    "            'spec_flux_var',\n",
    "            'zcr_mean',        # zero crossing rate mean and variance\n",
    "            'zcr_var',\n",
    "            'low_energy_rate', # low energy rate\n",
    "            'mfcc_1_mean',     # mean and variance of the first five MFCCs\n",
    "            'mfcc_2_mean',\n",
    "            'mfcc_3_mean',\n",
    "            'mfcc_4_mean',\n",
    "            'mfcc_5_mean',\n",
    "            'mfcc_1_var',\n",
    "            'mfcc_2_var',\n",
    "            'mfcc_3_var',\n",
    "            'mfcc_4_var',\n",
    "            'mfcc_5_var',\n",
    "                               # RHYTHM FEATURES\n",
    "            'rel_amp_peak_0',  # relative amplitudes of the two highest peaks between 40 and 200 bmp in tempogram\n",
    "            'rel_amp_peak_1',\n",
    "            'amp_ratio',       # ratio of the amplitudes of the two peaks\n",
    "            'freq_peak_0',     # frequencies in bpm of the two peaks\n",
    "            'freq_peak_1',\n",
    "            'tempogram_sum',   # sum of the tempogram amplitudes between 40 and 200 bpm\n",
    "            'beat_salience',   # beat salience\n",
    "                               # TONAL FEATURES\n",
    "            'pitch_amp',       # relative amplitude of the highest peak in the chromagram\n",
    "            'pitch_class',     # pitch class of the highest peak\n",
    "            'pitch_interval',  # interval between two highest peaks in the chromagram (distance on circle of fifths)\n",
    "            'chromagram_sum',  # sum of all chromagram amplitudes\n",
    "           ]\n",
    "\n",
    "multiindex = pd.MultiIndex.from_product([files.index, ['full', 'start', 'middle', 'end']], names=['file', 'section'])\n",
    "features = pd.DataFrame(index=multiindex, columns=features)\n",
    "\n",
    "frame_length = 1024\n",
    "\n",
    "for i, (index, row) in enumerate(files.iterrows()):\n",
    "    file = index\n",
    "    y, sr = librosa.load(row.path)\n",
    "    section = 'full'\n",
    "\n",
    "    # calculate section boundaries (inclusive)\n",
    "    l = len(y)\n",
    "    sections = [\n",
    "        ('full',   0,      l - 1),\n",
    "        ('start',  0,      l//3 - 1),\n",
    "        ('middle', l//3,   2*l//3 - 1),\n",
    "        ('end',    2*l//3, l - 1)\n",
    "    ]\n",
    "\n",
    "    for s in sections:\n",
    "        section = s[0]\n",
    "        y_section = y[s[1] : s[2] + 1]\n",
    "        \n",
    "        #### SPECTRAL CENTROID\n",
    "        spec_cent = librosa.feature.spectral_centroid(y=y_section, sr=sr, n_fft=frame_length, hop_length=frame_length, center=False)[0]\n",
    "        features.loc[(file, section), 'spec_cent_mean':'spec_cent_var'] = np.mean(spec_cent), np.var(spec_cent)\n",
    "\n",
    "        #### SPECTRAL ROLLOFF\n",
    "        spec_roll = librosa.feature.spectral_rolloff(y=y_section, sr=sr, n_fft=frame_length, hop_length=frame_length, center=False)[0]\n",
    "        features.loc[(file, section), 'spec_roll_mean':'spec_roll_var'] = np.mean(spec_roll), np.var(spec_roll)\n",
    "\n",
    "        #### SPECTRAL FLUX\n",
    "        spec_flux = spectral_flux(y=y_section, frame_length=frame_length)\n",
    "        features.loc[(file, section), 'spec_flux_mean':'spec_flux_var'] = np.mean(spec_flux), np.var(spec_flux)\n",
    "    \n",
    "        #### ZERO CROSSING RATE\n",
    "        zcr = librosa.feature.zero_crossing_rate(y=y_section, frame_length=frame_length, hop_length=frame_length, center=False)\n",
    "        features.loc[(file, section), 'zcr_mean':'zcr_var'] = np.mean(zcr), np.var(zcr)\n",
    "\n",
    "        #### LOW ENERGY RATE\n",
    "        ler = low_energy_rate(y=y_section, frame_length=frame_length)\n",
    "        features.loc[(file, section), 'low_energy_rate'] = ler\n",
    "\n",
    "        #### MFCC\n",
    "        mfcc = librosa.feature.mfcc(y=y_section, sr=sr, n_mfcc=5, n_fft=frame_length, hop_length=frame_length, center=False)\n",
    "        features.loc[(file, section), 'mfcc_1_mean':'mfcc_5_mean'] = np.mean(mfcc, axis=1)\n",
    "        features.loc[(file, section), 'mfcc_1_var':'mfcc_5_var'] = np.var(mfcc, axis=1)    \n",
    "\n",
    "        #### RHYTHM FEATURES\n",
    "        amp_0, amp_1, amp_r, freq_0, freq_1, tempogram_sum, beat_salience = rhythm_features(y=y_section, sr=sr, hop_length=128)\n",
    "        features.loc[(file, section), 'rel_amp_peak_0':'beat_salience'] = amp_0, amp_1, amp_r, freq_0, freq_1, tempogram_sum, beat_salience\n",
    "\n",
    "        #### TONAL FEATURES\n",
    "        amp_0, pitch_0, pitch_interval, chromagram_sum = tonal_features(y=y_section, sr=sr, frame_length=frame_length, hop_length=frame_length)\n",
    "        features.loc[(file, section), 'pitch_amp':'chromagram_sum'] = amp_0, pitch_0, pitch_interval, chromagram_sum\n",
    "    \n",
    "    #### PRINT PROGRESS\n",
    "    if (i+1)%5 == 0:\n",
    "        print(f'Processed file {i+1} of 1000 ({(i+1)/10}%)', end='\\r')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fed746-2c47-4f75-9a84-3b80735b9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f01e8be-7f62-4858-9998-2bdf4b79c7bb",
   "metadata": {},
   "source": [
    "### save DataFrame to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2327cc4-3fd7-479d-83e3-d181d5f9ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = features.join(files).drop(columns=['path'])\n",
    "full_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d4eb1d-e4ec-42ec-a89b-d26855a1b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'gtzan_features.csv'\n",
    "full_df.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aece7e-a501-486b-9b85-ebbaffcddb00",
   "metadata": {},
   "source": [
    "### normalise features and generate dataset splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093d8413-3755-47b1-8014-caeb105ff18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normalised = (features - features.min()) / (features.max() - features.min())\n",
    "features_normalised = features_normalised.join(files).drop(columns=['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc2157-7c94-4aad-8e9f-6868a6351a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normalised['split'] = features_normalised.apply(lambda x: int(x.name[0].split('.')[1]) % 5, axis=1)\n",
    "features_normalised['split'].xs('full', level='section').head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a38c7-19c2-403c-b78e-558b080aad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584d3ae-73b0-456f-97a5-ebb936394080",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path('./training_data').mkdir(exist_ok=True)\n",
    "for split in range(5):\n",
    "    df_train = features_normalised[features_normalised['split'] != split].drop(columns=['split'])\n",
    "    df_test  = features_normalised[features_normalised['split'] == split].drop(columns=['split'])\n",
    "\n",
    "    df_train.to_csv(f'training_data/train_{split}.csv')\n",
    "    df_test.to_csv(f'training_data/test_{split}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
